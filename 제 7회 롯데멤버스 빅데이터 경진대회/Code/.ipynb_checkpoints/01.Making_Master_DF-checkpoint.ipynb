{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 30) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pd.read_csv('../3.로티로리_데이터 및 모델 세이브 파일/LPOINT_BIG_COMP_01_DEMO.csv')\n",
    "pdde = pd.read_csv('../3.로티로리_데이터 및 모델 세이브 파일/LPOINT_BIG_COMP_02_PDDE.csv')\n",
    "cop_u = pd.read_csv('../3.로티로리_데이터 및 모델 세이브 파일/LPOINT_BIG_COMP_03_COP_U.csv')\n",
    "pd_clac = pd.read_csv('../3.로티로리_데이터 및 모델 세이브 파일/LPOINT_BIG_COMP_04_PD_CLAC.csv')\n",
    "br = pd.read_csv('../3.로티로리_데이터 및 모델 세이브 파일/LPOINT_BIG_COMP_05_BR.csv')\n",
    "lpay = pd.read_csv('../3.로티로리_데이터 및 모델 세이브 파일/LPOINT_BIG_COMP_06_LPAY.csv')\n",
    "\n",
    "Atmoshphere_df = pd.read_csv('../3.로티로리_데이터 및 모델 세이브 파일/Atmoshphere_df.csv')\n",
    "Weather_df = pd.read_csv('../3.로티로리_데이터 및 모델 세이브 파일/Weather_df.csv')\n",
    "Holiday_df = pd.read_csv('../3.로티로리_데이터 및 모델 세이브 파일/Holiday.csv',encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외부 데이터 preprocess\n",
    "Atmoshphere_df = Atmoshphere_df.iloc[:,1:]\n",
    "Weather_df = Weather_df.iloc[:,1:]\n",
    "\n",
    "Weather_df.rename(columns = {'region': 'zon_hlv_store', \n",
    "                               'date': 'de_dt'}, inplace=True)\n",
    "\n",
    "Atmoshphere_df.rename(columns = {'region': 'zon_hlv_store', \n",
    "                               'date': 'de_dt'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1번 데모 데이터 크기: ', demo.shape)\n",
    "print('2번 유통사구매 데이터 크기: ', pdde.shape)\n",
    "print('3번 유통사 제외 제휴사 데이터 크기: ', cop_u.shape)\n",
    "print('4번 물품품목 데이터 크기: ', pd_clac.shape)\n",
    "print('5번 점포구분 데이터 크기: ', br.shape)\n",
    "print('6번 엘페이 데이터 크기: ', lpay.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유통사 구매DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유통사관련 정보 merge\n",
    "def make_merged_store(pdde, pd_clac, demo, br):\n",
    "    # 유통사 구매데이터와 상품 정보 merge\n",
    "    store_info = pd.merge(pdde, pd_clac, on = 'pd_c')\n",
    "\n",
    "    # 해당 정보와 점포정보 merge\n",
    "    ## cop_c 정보 겹쳐서 하나 제거\n",
    "    store_info = pd.merge(store_info ,br.drop('cop_c', axis = 1) ,how = 'left', on='br_c')\n",
    "\n",
    "    # 해당 정보와 cust 정보 merge\n",
    "    ## zon_hlv가 겹치니 suffix 생성\n",
    "    store_info = pd.merge(store_info, demo, on='cust', suffixes =('_store', '_cust'))\n",
    "    \n",
    "    return store_info\n",
    "\n",
    "store_info = make_merged_store(pdde, pd_clac, demo, br)\n",
    "store_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_info['br_c'].fillna('점포없음', inplace=True)\n",
    "store_info['zon_hlv_store'].fillna('점포없음', inplace=True)\n",
    "store_info['zon_mcls'].fillna('점포없음', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제휴사 구매DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제휴사 관련 정보 merge\n",
    "def make_merged_cop(cop_u, demo, br):\n",
    "    cop_info = pd.merge(cop_u, demo, on = 'cust')\n",
    "    cop_info = pd.merge(cop_info, br.drop('cop_c', axis=1).rename(columns={'zon_hlv': 'zon_hlv_cop',\n",
    "                                           'zon_mcls': 'zon_mcls_cop'}),\n",
    "                        on = 'br_c', how = 'left')\n",
    "\n",
    "    cop_info.rename({'zon_hlv': 'zon_hlv_cust'}, inplace = True)\n",
    "    return cop_info\n",
    "\n",
    "cop_info = make_merged_cop(cop_u, demo, br)\n",
    "cop_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cop_info['br_c'].fillna('점포없음', inplace = True)\n",
    "cop_info['zon_hlv_cop'].fillna('점포없음', inplace = True)\n",
    "cop_info['zon_mcls_cop'].fillna('점포없음', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lpay DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lpay 관련 정보 merge\n",
    "def make_merged_lpay(lpay, demo):\n",
    "    lpay_info = pd.merge(lpay, demo)\n",
    "    \n",
    "    return lpay_info\n",
    "\n",
    "lpay_info = make_merged_lpay(lpay, demo)\n",
    "lpay_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이용고객"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('유통사 이용 고객 수: ', len(set(store_info.cust)))\n",
    "print('제휴사 이용 고객 수: ',len(set(cop_info.cust)))\n",
    "print('엘페이 이용 고객 수: ', len(set(lpay.cust)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석에 사용할 데이터프레임 명명\n",
    "\n",
    "def define_dataframe(store_info, cop_info, lpay_info):\n",
    "    tp_df = pd.merge(store_info.groupby('cust')['buy_ct'].mean().reset_index(),cop_info.groupby('cust')['buy_am'].mean().reset_index(), on = 'cust', how = 'inner' )\n",
    "    experience_cust_lst = pd.merge(store_info.groupby('cust')['buy_ct'].mean().reset_index(),cop_info.groupby('cust')['buy_am'].mean().reset_index(), on = 'cust', how = 'inner' )['cust'].tolist()\n",
    "    experience_lpay_cust_lst = pd.merge(tp_df, lpay_info.groupby('cust')['de_hr'].mean().reset_index(), on = 'cust', how = 'inner')['cust'].tolist()\n",
    "    \n",
    "    store_df = store_info[store_info['cust'].isin(experience_cust_lst)].reset_index().iloc[:,1:]\n",
    "    cop_df = cop_info[cop_info['cust'].isin(experience_cust_lst)].reset_index().iloc[:,1:]\n",
    "    lpay_df = lpay_info[lpay_info['cust'].isin(experience_lpay_cust_lst)].reset_index().iloc[:,1:]\n",
    "    lpay_df = lpay_df[(lpay_df['cop_c'] != 'L01')&(lpay_df['cop_c'] != 'L00')]\n",
    "    \n",
    "    experience_df = pd.concat([store_df,cop_df], axis = 0)       # 제휴사와 유통사 데이터를 concat한 데이터 프레임\n",
    "    experience_df = experience_df.drop('zon_hlv', axis = 1)\n",
    "    \n",
    "    return experience_df, lpay_df, experience_cust_lst, experience_lpay_cust_lst\n",
    "\n",
    "master_df, lpay_df, experience_cust_lst, experience_lpay_cust_lst = define_dataframe(store_info, cop_info, lpay_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('온/오프라인 제휴사 및 유통사를 이용하는 고객 수: ', len(experience_cust_lst))\n",
    "print('제휴사 및 유통사를 이용하면서 엘페이를 이용한 고객 수: ', len(experience_lpay_cust_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유통사와 제휴사를 모두 이용한 고객 중 lpay를 사용한 고객 / 안한고객에 대한 리스트를 구함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 외부데이터 병합\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주말/공휴일 데이터 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_list = Holiday_df.Date.unique().tolist()\n",
    "master_holiday = []\n",
    "for i in master_df.de_dt:\n",
    "    if i in holiday_list:\n",
    "        master_holiday.append(1)\n",
    "    else:\n",
    "        master_holiday.append(0)\n",
    "        \n",
    "master_df['weekend_holiday'] = master_holiday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 날씨정보 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def merging_weather_df(master_df):\n",
    "    # cop랑 store 따로 해야해서 일단 떼놓기\n",
    "    tp_cop = master_df.iloc[3558050: ,:]\n",
    "    tp_store = master_df.iloc[:3558050 ,:]\n",
    "\n",
    "    # 온라인에서 산 녀석들은 점포정보가 없어서 cust 주소로 붙여야 함\n",
    "    # 근데 한번에 붙이기 위해서 다음과 같이 cust 주소를 store 주소로 임시 대체\n",
    "    tp_values = tp_store[tp_store['zon_hlv_store'] == '점포없음']['zon_hlv_cust'].values\n",
    "    tp_store.loc[tp_store['zon_hlv_store'] == '점포없음', 'zon_hlv_store'] = tp_values\n",
    "    # store 정보와 weather 병합\n",
    "    tp_store = pd.merge(tp_store , Weather_df, on=['zon_hlv_store', 'de_dt'], how ='left')\n",
    "\n",
    "    # 온라인에 대한 점포정보가 없어서 가져와주기\n",
    "    zon_need_cust_lst = list(tp_cop.loc[(tp_cop.zon_hlv_cop == '점포없음')].cust)\n",
    "    cust_zon_info_lst = tp_store[tp_store['cust'].isin(zon_need_cust_lst)].groupby('cust').zon_hlv_cust.first()\n",
    "    cust_zon_info_lst_2 = pd.merge(tp_cop.loc[(tp_cop.zon_hlv_cop == '점포없음')],pd.DataFrame(tp_store[tp_store['cust'].isin(zon_need_cust_lst)].groupby('cust').zon_hlv_cust.first()).reset_index() , on = 'cust',\n",
    "        how = 'left')['zon_hlv_cust_y'].values\n",
    "    \n",
    "    # 점포 없음에다 정보 채우기\n",
    "    tp_cop.loc[(tp_cop.zon_hlv_cop == '점포없음'), 'zon_hlv_cop'] = cust_zon_info_lst_2\n",
    "    Weather_df.rename(columns = {'zon_hlv_store': 'zon_hlv_cop'}, inplace=True)\n",
    "    # 정보 임시 cop에 머징\n",
    "    tp_cop = pd.merge(tp_cop, Weather_df, on=['zon_hlv_cop', 'de_dt'], how ='left')\n",
    "    \n",
    "    #2020년 정보가 없어 채워지지 않았기 때문에 20210101로 전부 대체\n",
    "#     temper = pd.merge(tp_cop[tp_cop.temperature.isna()], Weather_df[Weather_df.de_dt == 20210101], on ='zon_hlv_cop', how = 'left')['temperature_y'].values\n",
    "#     rainfall = pd.merge(tp_cop[tp_cop.rainfall.isna()], Weather_df[Weather_df.de_dt == 20210101], on ='zon_hlv_cop', how = 'left')['rainfall_y'].values\n",
    "#     ht = pd.merge(tp_cop[tp_cop.huminity.isna()], Weather_df[Weather_df.de_dt == 20210101], on ='zon_hlv_cop', how = 'left')['huminity_y'].values\n",
    "#     tp_cop.loc[tp_cop.temperature.isna(), 'temperature'] = temper\n",
    "#     tp_cop.loc[tp_cop.rainfall.isna(), 'rainfall'] = rainfall\n",
    "#     tp_cop.loc[tp_cop.huminity.isna(), 'huminity'] = ht\n",
    "    \n",
    "    # 다시 master_df로 리턴\n",
    "    master_df = pd.concat([tp_store, tp_cop], axis = 0)\n",
    "    return master_df\n",
    "\n",
    "master_df = merging_weather_df(master_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 대기정보 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 기상청 정보기준으로 중부 남부 제주 나누기\n",
    "def merging_atmosphere_df(master_df):\n",
    "    def change_zone_to_area(x):\n",
    "        if x == 'Z03'or x == 'Z05'or x == 'Z06'or x == 'Z11'or x == 'Z12'or x == 'Z13'or x == 'Z14'or x == 'Z16':\n",
    "            return '남부'\n",
    "        elif x == 'Z07':\n",
    "            return '제주'\n",
    "        elif x == 'Z01'or x == 'Z02'or x == 'Z04'or x == 'Z08'or x == 'Z09'or x == 'Z10'or x == 'Z15'or x == 'Z17' :\n",
    "            return '중부'\n",
    "\n",
    "    # cop랑 store 따로 해야해서 일단 떼놓기\n",
    "    tp_cop = master_df.iloc[3558050: ,:]\n",
    "    tp_store = master_df.iloc[:3558050 ,:]\n",
    "\n",
    "    # store 정보 handling\n",
    "    tp_values = tp_store[tp_store['zon_hlv_store'] == '점포없음']['zon_hlv_cust'].values\n",
    "    tp_store.loc[tp_store['zon_hlv_store'] == '점포없음', 'zon_hlv_store'] = tp_values\n",
    "    tp_store.loc[:, 'zon_area'] = tp_store['zon_hlv_store'].apply(change_zone_to_area)\n",
    "\n",
    "    Atmoshphere_df.rename(columns = {'region_at' : 'zon_area'}, inplace=True)\n",
    "\n",
    "    # store 정보와 atmos 병합\n",
    "    tp_store = pd.merge(tp_store , Atmoshphere_df, on=['de_dt', 'zon_area'], how ='left')\n",
    "\n",
    "    # cop 정보 handling\n",
    "    zon_need_cust_lst = list(tp_cop[tp_cop.zon_hlv_cop == '점포없음'].cust)\n",
    "    cust_zon_info_lst = tp_store[tp_store['cust'].isin(zon_need_cust_lst)].groupby('cust').zon_hlv_cust.first()\n",
    "    cust_zon_info_lst_2 = pd.merge(tp_cop.loc[(tp_cop.zon_hlv_cop == '점포없음')],pd.DataFrame(tp_store[tp_store['cust'].isin(zon_need_cust_lst)].groupby('cust').zon_hlv_cust.first()).reset_index() , on = 'cust',\n",
    "            how = 'left')['zon_hlv_cust_y'].values\n",
    "    tp_cop.loc[(tp_cop.zon_hlv_cop == '점포없음'), 'zon_hlv_cop'] = cust_zon_info_lst_2\n",
    "    tp_cop['zon_area'] = tp_cop.loc[:, 'zon_hlv_cop'].apply(change_zone_to_area)\n",
    "\n",
    "    # cop 정보와 atmos 병합\n",
    "    tp_cop = pd.merge(tp_cop , Atmoshphere_df, on=['de_dt', 'zon_area'], how ='left')\n",
    "\n",
    "    # 다시 master_df로 리턴\n",
    "    master_df = pd.concat([tp_store, tp_cop], axis = 0)\n",
    "    return master_df\n",
    "\n",
    "\n",
    "master_df = merging_atmosphere_df(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리셋인덱스\n",
    "master_df.reset_index(drop='first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_deploy = master_df.copy()\n",
    "lpay_df_deploy = lpay_df.reset_index(drop = True)\n",
    "\n",
    "master_df_deploy.to_csv('../3.로티로리_데이터 및 모델 세이브 파일/Master DF.csv')\n",
    "lpay_df_deploy.to_csv('../3.로티로리_데이터 및 모델 세이브 파일/Refine lpay DF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quater Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2020년 데이터 삭제\n",
    "before_2021_lst =master_df[master_df.de_dt < 20210101].index\n",
    "master_df.drop(before_2021_lst, axis = 0, inplace = True)\n",
    "master_df.reset_index(drop='first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_quater = []\n",
    "for i in master_df.de_dt:\n",
    "    if i < 20210401 and i >= 20210101:\n",
    "        master_quater.append(1)\n",
    "    elif i < 20210701:\n",
    "        master_quater.append(2)\n",
    "    elif i < 20211001:\n",
    "        master_quater.append(3)\n",
    "    else:\n",
    "        master_quater.append(4)    \n",
    "master_df['quater'] = master_quater\n",
    "\n",
    "lpay_quater = []\n",
    "for j in lpay_df.de_dt:\n",
    "    if j < 20210401 and i >= 20210101:\n",
    "        lpay_quater.append(1)\n",
    "    elif j < 20210701:\n",
    "        lpay_quater.append(2)\n",
    "    elif j < 20211001:\n",
    "        lpay_quater.append(3)\n",
    "    else:\n",
    "        lpay_quater.append(4)\n",
    "lpay_df['quater'] = lpay_quater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lpay_use_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_chnl(x):\n",
    "    if len(x) == 1:\n",
    "        if x[0] == 1:\n",
    "            return 'Lpay_Offline'\n",
    "        else:\n",
    "            return 'Lpay_Online'\n",
    "    else:\n",
    "        return 'Lpay_On/Offline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 2 분기 train\n",
    "master_quater12 = master_df.query('quater == 1 or quater == 2 ').reset_index(drop=True)\n",
    "lpay_df12 = lpay_df.query('quater == 1 or quater == 2 ').reset_index(drop=True)\n",
    "\n",
    "lpay_df12 = pd.merge(lpay_df12,  pd.DataFrame(lpay_df12.groupby('cust')['chnl_dv'].unique().apply(divide_chnl)).reset_index().rename(columns = {'chnl_dv': 'lpay_use_status'}),  on='cust')\n",
    "master_quater12 =  pd.merge(master_quater12, lpay_df12.groupby('cust')['lpay_use_status'].unique().apply(lambda x : x[0]).reset_index(), on = 'cust', how ='left')\n",
    "master_quater12['lpay_use_status'].fillna('Lpay_X', inplace = True)\n",
    "master_quater12.fillna('정보없음', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3분기 test\n",
    "master_quater3 = master_df.query('quater == 3').reset_index(drop=True)\n",
    "lpay_df3 = lpay_df.query('quater == 3').reset_index(drop=True)\n",
    "\n",
    "lpay_df3 = pd.merge(lpay_df3,  pd.DataFrame(lpay_df3.groupby('cust')['chnl_dv'].unique().apply(divide_chnl)).reset_index().rename(columns = {'chnl_dv': 'lpay_use_status'}),  on='cust')\n",
    "master_quater3 =  pd.merge(master_quater3, lpay_df3.groupby('cust')['lpay_use_status'].unique().apply(lambda x : x[0]).reset_index(), on = 'cust', how ='left')\n",
    "master_quater3['lpay_use_status'].fillna('Lpay_X', inplace = True)\n",
    "master_quater3.fillna('정보없음', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 3분기 train\n",
    "master_quater23 = master_df.query('quater == 2 or quater == 3 ').reset_index(drop=True)\n",
    "lpay_df23 = lpay_df.query('quater == 2 or quater == 3 ').reset_index(drop=True)\n",
    "\n",
    "lpay_df23 = pd.merge(lpay_df23,  pd.DataFrame(lpay_df23.groupby('cust')['chnl_dv'].unique().apply(divide_chnl)).reset_index().rename(columns = {'chnl_dv': 'lpay_use_status'}),  on='cust')\n",
    "master_quater23 =  pd.merge(master_quater23, lpay_df23.groupby('cust')['lpay_use_status'].unique().apply(lambda x : x[0]).reset_index(), on = 'cust', how ='left')\n",
    "master_quater23['lpay_use_status'].fillna('Lpay_X', inplace = True)\n",
    "master_quater23.fillna('정보없음', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4분기 test\n",
    "master_quater4 = master_df.query('quater == 4 ').reset_index(drop=True)\n",
    "lpay_df4 = lpay_df.query('quater == 4 ').reset_index(drop=True)\n",
    "\n",
    "lpay_df4 = pd.merge(lpay_df4,  pd.DataFrame(lpay_df4.groupby('cust')['chnl_dv'].unique().apply(divide_chnl)).reset_index().rename(columns = {'chnl_dv': 'lpay_use_status'}),  on='cust')\n",
    "master_quater4 =  pd.merge(master_quater4, lpay_df4.groupby('cust')['lpay_use_status'].unique().apply(lambda x : x[0]).reset_index(), on = 'cust', how ='left')\n",
    "master_quater4['lpay_use_status'].fillna('Lpay_X', inplace = True)\n",
    "master_quater4.fillna('정보없음', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_quater12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_quater3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_quater23.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_quater4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_quater12.to_csv('../3.로티로리_데이터 및 모델 세이브 파일/Master_DF12_tr.csv',index= False)\n",
    "master_quater3.to_csv('../3.로티로리_데이터 및 모델 세이브 파일/Master_DF3_te.csv',index= False)\n",
    "master_quater23.to_csv('../3.로티로리_데이터 및 모델 세이브 파일/Master_DF23_tr.csv',index= False)\n",
    "master_quater4.to_csv('../3.로티로리_데이터 및 모델 세이브 파일/Master_DF4_te.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpay_df12.to_csv('../3.로티로리_데이터 및 모델 세이브 파일/Lpay_DF12.csv',index= False)\n",
    "lpay_df3.to_csv('../3.로티로리_데이터 및 모델 세이브 파일/Lpay_DF3.csv',index= False)\n",
    "lpay_df23.to_csv('../3.로티로리_데이터 및 모델 세이브 파일/Lpay_DF23.csv',index= False)\n",
    "lpay_df4.to_csv('../3.로티로리_데이터 및 모델 세이브 파일/Lpay_DF4.csv',index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
